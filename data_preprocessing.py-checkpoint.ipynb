{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdba0b-bbff-4630-95b2-4477a0dc3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Data directory does not exist: {data_dir}\")\n",
    "        return None, None\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust based on your image format\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "\n",
    "            # Construct the corresponding mask filename\n",
    "            mask_filename = filename + \"_mask.jpg\"  # Adjust the extension if needed\n",
    "            mask_path = os.path.join(data_dir, mask_filename)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "            else:\n",
    "                print(f\"Missing mask for: {filename}\")\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Specify your dataset directory\n",
    "data_dir = r\"C:\\Users\\Admin\\Desktop\\brain mri\\Data\\TCGA_CS_4941_19960909\"  # Use raw string to avoid escape issues\n",
    "images, masks = load_data(data_dir)\n",
    "\n",
    "# Optionally, check the shapes of loaded images and masks\n",
    "if images is not None and masks is not None:\n",
    "    print(f\"Loaded {len(images)} images and {len(masks)} masks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55ebf7-6135-4cd3-a7e2-33af8761707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bdaf3-2927-45e8-98cf-1d4de241514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8287a-f5a7-48f5-a388-fad9d083bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(image_dir, mask_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        mask_path = os.path.join(mask_dir, filename)\n",
    "\n",
    "        if os.path.exists(image_path) and os.path.exists(mask_path):\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            images.append(image)\n",
    "            masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "image_dir = \"../dataset/images/\"\n",
    "mask_dir = \"../dataset/masks/\"\n",
    "\n",
    "images, masks = load_data(image_dir, mask_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae495ff2-c7b3-4034-bd11-8f14cdfe2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(image)\n",
    "\n",
    "# Apply CLAHE to all images\n",
    "images = np.array([apply_clahe(img) for img in images])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49306da-301e-4431-8491-e92e09e83d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "    return images / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Normalize images\n",
    "images = normalize(images)\n",
    "masks = normalize(masks)\n",
    "\n",
    "# Split the dataset\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc85f4a-c9b5-4558-8cef-06b1531bba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Data directory does not exist: {data_dir}\")\n",
    "        return None, None\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        print(f\"Processing file: {filename}\")  # Debugging line\n",
    "\n",
    "        # Check for supported image formats\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.tif')):  # Add other formats if necessary\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "\n",
    "            # Construct the corresponding mask filename\n",
    "            mask_filename = filename.replace('.tif', '_mask.tif')  # Adjust if needed\n",
    "            mask_path = os.path.join(data_dir, mask_filename)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                images.append(image)\n",
    "                masks.append(mask)\n",
    "            else:\n",
    "                print(f\"Missing mask for: {filename}\")\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Specify your dataset directory\n",
    "data_dir = r\"C:\\Users\\Admin\\Desktop\\brain mri\\dataset\"\n",
    "images, masks = load_data(data_dir)\n",
    "\n",
    "# Optionally, check the shapes of loaded images and masks\n",
    "if images is not None and masks is not None:\n",
    "    print(f\"Loaded {len(images)} images and {len(masks)} masks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf2353-649a-409d-98f0-617754e24802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "    processed_images = []\n",
    "    for image in images:\n",
    "        # Apply CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        clahe_image = clahe.apply(image)\n",
    "        \n",
    "        # Normalize the image\n",
    "        normalized_image = clahe_image / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        processed_images.append(normalized_image)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Preprocess the loaded images\n",
    "processed_images = preprocess_images(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44bc268-8e67-4aec-b97b-7593800622cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(processed_images, masks, test_size=0.2, random_state=42)\n",
    "print(f\"Training images: {len(train_images)}, Training masks: {len(train_masks)}\")\n",
    "print(f\"Testing images: {len(test_images)}, Testing masks: {len(test_masks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238f1bc-6814-45f4-a35e-07777f0315e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "\n",
    "# Example for a simple U-Net model\n",
    "def unet_model(input_size=(256, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    # Define your U-Net architecture here\n",
    "    # ...\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(last_layer)  # Change as necessary\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f3aee-f2c4-4205-9f2d-7aeb6374e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f4d44-3333-4e5a-8543-e640d95d81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad0786-1b99-4046-8aa5-13c76282061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # This will print the TensorFlow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfbd88-7560-4b96-a47e-fd54787cb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106309b3-e2ae-48a4-ba56-6729f3a37d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "\n",
    "# Example for a simple U-Net model\n",
    "def unet_model(input_size=(256, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    # Define your U-Net architecture here\n",
    "    # ...\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(last_layer)  # Change as necessary\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160be18-2506-4889-991a-3a2a4745dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(input_size=(256, 256, 1))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_masks, validation_split=0.2, epochs=50, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08925e6-49e0-4520-94cf-4cc811c2254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_masks)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Calculate DICE Score\n",
    "def dice_score(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
    "\n",
    "# Assuming binary segmentation, threshold predictions\n",
    "predictions = model.predict(test_images)\n",
    "predictions = (predictions > 0.5).astype(np.uint8)\n",
    "\n",
    "dice = dice_score(test_masks, predictions)\n",
    "print(f\"DICE Score: {dice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc68c62-c1da-468d-8f8a-229f6b7eac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "\n",
    "def nested_unet(input_shape=(256, 256, 1)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder path\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Decoder path\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    merge6 = concatenate([up6, conv4])\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    merge7 = concatenate([up7, conv3])\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    merge8 = concatenate([up8, conv2])\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    merge9 = concatenate([up9, conv1])\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)  # Sigmoid activation for binary segmentation\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "nested_unet_model = nested_unet()\n",
    "nested_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8928b30-926f-4942-a94a-a9e552e56b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply, Activation\n",
    "\n",
    "def attention_block(x, g):\n",
    "    g = Conv2D(x.shape[-1], (1, 1))(g)\n",
    "    x = Conv2D(x.shape[-1], (1, 1))(x)\n",
    "    \n",
    "    # Add and activate\n",
    "    attention_coefficients = Activation('sigmoid')(Add()([x, g]))\n",
    "    return Multiply()([x, attention_coefficients])\n",
    "\n",
    "def attention_unet(input_shape=(256, 256, 1)):\n",
    "    inputs = Input(input_shape)\n",
    "    # Define the encoder path (similar to U-Net)...\n",
    "    # Use the attention_block at the merge points in the decoder path\n",
    "    \n",
    "    # Example merge point:\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)  # conv5 from encoder\n",
    "    merge6 = concatenate([up6, conv4])  # conv4 from encoder\n",
    "    attention6 = attention_block(conv4, up6)  # Apply attention\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(attention6)\n",
    "    # Continue defining the model...\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "attention_unet_model = attention_unet()\n",
    "attention_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973fbb8c-9c56-40aa-9709-bbef14d1713c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f7e77-b0f7-46c7-be32-7881d62df874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Nested U-Net\n",
    "history_nested = nested_unet_model.fit(train_images, train_masks, \n",
    "                                        validation_split=0.2, \n",
    "                                        epochs=50, \n",
    "                                        batch_size=16)\n",
    "\n",
    "# Train Attention U-Net\n",
    "history_attention = attention_unet_model.fit(train_images, train_masks, \n",
    "                                              validation_split=0.2, \n",
    "                                              epochs=50, \n",
    "                                              batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95758b-aab2-4230-a79c-05e83d1653f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Nested U-Net\n",
    "test_loss, test_accuracy = nested_unet_model.evaluate(test_images, test_masks)\n",
    "print(f\"Nested U-Net - Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Evaluate Attention U-Net\n",
    "test_loss, test_accuracy = attention_unet_model.evaluate(test_images, test_masks)\n",
    "print(f\"Attention U-Net - Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# DICE Score calculation\n",
    "def calculate_dice(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
    "\n",
    "# Threshold predictions and calculate DICE scores\n",
    "nested_predictions = (nested_unet_model.predict(test_images) > 0.5).astype(np.uint8)\n",
    "attention_predictions = (attention_unet_model.predict(test_images) > 0.5).astype(np.uint8)\n",
    "\n",
    "dice_nested = calculate_dice(test_masks, nested_predictions)\n",
    "dice_attention = calculate_dice(test_masks, attention_predictions)\n",
    "\n",
    "print(f\"Nested U-Net DICE Score: {dice_nested}\")\n",
    "print(f\"Attention U-Net DICE Score: {dice_attention}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6d4e8-3838-4f96-b2b4-a41fc6326328",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff148941-ca18-49eb-8a5f-1a0f9498a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    # Load and preprocess the uploaded image\n",
    "    # Use your model to make predictions\n",
    "    # Return predictions\n",
    "    return JSONResponse(content={\"message\": \"Prediction results\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f126947-f363-4815-bd62-30dcd38c6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "st.title(\"Brain MRI Metastasis Segmentation\")\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
    "    \n",
    "    if st.button(\"Predict\"):\n",
    "        # Send the image to the FastAPI endpoint and get predictions\n",
    "        # Display results\n",
    "        st.write(\"Prediction results will be shown here.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d64e2-7856-4c87-8a11-0776b4249fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27333f0c-89ba-4b13-b36a-9c840d89b657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d08cc-956d-4412-a02b-4f23ef00385f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944e98e-6fb1-41cf-a882-53da9f69b6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
